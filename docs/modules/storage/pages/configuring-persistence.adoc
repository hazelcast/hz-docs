= Persistence Configuration Options
:description: Explore the options for configuring peristence on your members.

{description}

== Global Persistence Configuration

Use the following options to configure the `persistence` object on your members.

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <!-- insert global configuration options here -->
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    # insert global configuration options here
----
--
Java:: 
+ 
--
Add global configuration options to the link:https://docs.hazelcast.org/docs/{page-component-version}/javadoc/com/hazelcast/config/PersistenceConfig.html[`PersistenceConfig` object].

[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

[cols="1a,1a,1m,2a",options="header"]
|===
|Option|Description|Default|Example



|[[persistence-base-dir]]`base-dir`
|The parent directory in which to store persisted data.

This directory is created automatically if it does not exist.

|persistence
|

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <base-dir>
      /path/to/persistence
    </base-dir>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    base-dir: /path/to/persistence
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setBaseDir(new File("/path/to/persistence"));

config.setPersistenceConfig(PersistenceConfig);
----
--
====


|[[persistence-backup-dir]]`backup-dir`
|The directory in which to store backup snapshots
(hot backups).

a|'' (empty)

|
See xref:backing-up-persistence.adoc[].

|[[persistence-parallelism]]`parallelism`
|Number of I/O threads that are started concurrently for reading from and writing to files in the persistence store.


Before changing the default, you should measure the raw I/O throughput of your infrastructure and
test with different values of parallelism. In some cases, such as dedicated
hardware, higher parallelism can yield more throughput. In other
cases, such as running on EC2, a higher parallelism can yield diminishing returns with more thread
scheduling, more contention on I/O, and less efficient garbage collection.

|`1`

|
[tabs]
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <parallelism>
      2
    </parallelism>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    parallelism: 2
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setParallelism(2);

config.setPersistenceConfig(PersistenceConfig);
----
--
====


|[[persistence-validation-timeout-seconds]]`validation-timeout-seconds`
|Amount of time that the cluster waits before starting the <<partitioned.cluster-data-recovery-policy, data recovery process>>.
|120

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <validation-timeout-seconds>
      120
    </validation-timeout-seconds>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    validation-timeout-seconds: 120
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setValidationTimeoutSeconds(120);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

[[persistence-data-load-timeout-seconds]]
|`data-load-timeout-seconds`
|Amount of time in seconds that the cluster allows for members to finish restoring their local data.
|900

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <data-load-timeout-seconds>
      900
    </data-load-timeout-seconds>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    data-load-timeout-seconds: 900
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setDataLoadTimeoutSeconds(900);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

|[[persistence-cluster-data-recovery-policy]]`cluster-data-recovery-policy`
|The data recovery policy that is
respected when the cluster restarts.

Valid values are:

* `FULL_RECOVERY_ONLY`: Starts the cluster only when all expected members
are present and correct.
* `PARTIAL_RECOVERY_MOST_RECENT`: Starts the cluster with the members that have most up-to-date partition table and successfully restored their data. All other members leave the cluster and force start themselves. If no members restore their data successfully, the cluster start fails.
* `PARTIAL_RECOVERY_MOST_COMPLETE`: Starts the cluster with the largest group of members that have the same partition table version and successfully restored their data. All other members leave the cluster and force start themselves. If no members restore their data successfully, the cluster start fails.
|FULL_RECOVERY_ONLY

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <cluster-data-recovery-policy>
      FULL_RECOVERY_ONLY
    </cluster-data-recovery-policy>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    cluster-data-recovery-policy: FULL_RECOVERY_ONLY
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setClusterDataRecoveryPolicy(PersistenceClusterDataRecoveryPolicy.FULL_RECOVERY_ONLY);

config.setPersistenceConfig(PersistenceConfig);
----
--
====

[[persistence-auto-remove-stale-data]]
|`auto-remove-stale-data`
|Enables a joining member to automatically remove its persistence store if the cluster's master member considers the peristed data to be stale. See xref:recover-single-member.adoc[].
|true

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <persistence enabled="true">
    <auto-remove-stale-data>
      true
    </auto-remove-stale-data>
  </persistence>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    auto-remove-stale-data: true
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

PersistenceConfig PersistenceConfig = new PersistenceConfig()
.setEnabled(true)
.setAutoRemoveStaleData(true);

config.setPersistenceConfig(PersistenceConfig);
----
--
====


|[[persistence-encryption-at-rest]]`encryption-at-rest`
|Enables encryption of data in the persistence store.
|disabled
|See xref:encryption-at-rest.adoc[].

|===

== Data Structure Persistence Configuration

Use the following options to configure persistence for xref:data-structures:map.adoc[map] and xref:jcache:overview.adoc[JCache] data structures.

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <map name="test-map">
    <data-persistence enabled="true">
      <!-- insert configuration options here -->
    </data-persistence>
  </map>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  map:
  test-map:
    data-persistence:
      enabled: true
      # insert configuration options here
----
--
Java:: 
+ 
--
Add configuration options to the link:https://docs.hazelcast.org/docs/{page-component-version}/javadoc/com/hazelcast/config/MapConfig.html[`MapConfig` object].

[source,java]
----
Config config = new Config();

MapConfig mapConfig = config.getMapConfig("test-map");
mapConfig.getDataPersistenceConfig().setEnabled(true);

config.addMapConfig(mapConfig);
----
--
====

[cols="1a,1a,1m,2a",options="header"]
|===
|Option|Description|Default|Example


|[[persistence-fsync]]`fsync`
|Guarantees that data is persisted to disk when a write operation returns a successful response to the caller.

By default, data is eventually persisted to disk instead of on every disk write. This generally provides a better performance.
|false

|
[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <map name="test-map">
    <data-persistence enabled="true">
      <fsync>
        false
      <fsync>
    </data-persistence>
  </map>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  map:
  test-map:
    data-persistence:
      enabled: true
      fsync: false
----
--
Java:: 
+ 
--
[source,java]
----
Config config = new Config();

MapConfig mapConfig = config.getMapConfig("test-map");
mapConfig.getDataPersistenceConfig().setEnabled(true)
.setFsync(true);

config.addMapConfig(mapConfig);
----
--
====

|`merkle-tree`
|Allows restarting members to synchronize their persisted map or JCache data faster with the rest of the cluster.

Although this option is not unique to persistence (map Merkle trees are also used for xref:wan:advanced-features.adoc[WAN delta synchronization]), we strongly recommended enabling it for each map or JCache data structure that you want to persist on disk.
|disabled

|See xref:recover-single-member.adoc#synchronizing-data-faster[Synchronizing Data Faster] for more information.
|===

== Job Snapshot Configuration

Use the following option to configure persistence for xref:pipelines:overview.adoc[job snapshots].

[tabs] 
==== 
XML:: 
+ 
--
[source,xml]
----
<hazelcast>
  <jet>
    <instance>
      <lossless-restart-enabled>
      true
      </lossless-restart-enabled>
    </instance>
  </jet>
</hazelcast>
----
--
YAML:: 
+ 
--
[source,yaml]
----
hazelcast:
  jet:
    instance:
      lossless-restart-enabled: true
----
--
Java:: 
+ 
--
Use the link:https://docs.hazelcast.org/docs/{page-component-version}/javadoc/com/hazelcast/jet/config/JetConfig.html[`JetConfig` object].

[source,java]
----
Config config = new Config();
config.getJetConfig().setLosslessRestartEnabled(true);
----
--
====

For lossless restart to work, the cluster must be xref:maintain-cluster:shutdown.adoc#graceful-shutdown[shut down gracefully].
When members are shut down in a rapid succession, Hazelcast triggers
an automatic rebalancing process where backup partitions are promoted
and new backups are created for each member. This may result in
out-of-memory errors or data loss.

Because job data is saved locally on each member, all
members must be present after a restart for Hazelcast to be able to reload
the data.

== Full Example of Persistence Configuration

The following are example configuration settings for a map instance, a JCache instance, and the Jet engine.

[tabs] 
==== 
XML:: 
+ 
-- 
[source,xml]
----
<hazelcast>
    ...
    <persistence enabled="true">
      <base-dir>/mnt/persistence</base-dir>
      <backup-dir>/mnt/hot-backup</backup-dir>
      <validation-timeout-seconds>120</validation-timeout-seconds>
      <data-load-timeout-seconds>900</data-load-timeout-seconds>
      <cluster-data-recovery-policy>FULL_RECOVERY_ONLY</cluster-data-recovery-policy>
    </persistence>
    ...
    <map name="test-map">
      <merkle-tree enabled="true" >
        <depth>12</depth>
      </merkle-tree>
      <data-persistence enabled="true">
        <fsync>false</fsync>
      </data-persistence>
    </map>
    ...
    <cache name="test-cache">
      <merkle-tree enabled="true" >
        <depth>12</depth>
      </merkle-tree>
      <data-persistence enabled="true">
          <fsync>false</fsync>
      </data-persistence>
    </cache>
    ...
    <jet>
      <instance>
        <lossless-restart-enabled>true</lossless-restart-enabled>
      </instance>
    </jet>
    ...
</hazelcast>
----
--

YAML::
+
--
[source,yaml]
----
hazelcast:
  persistence:
    enabled: true
    base-dir: /mnt/persistence
    backup-dir: /mnt/hot-backup
    validation-timeout-seconds: 120
    data-load-timeout-seconds: 900
    cluster-data-recovery-policy: FULL_RECOVERY_ONLY
  map:
    test-map:
      merkle-tree:
        enabled: true
        depth: 12
      data-persistence:
        enabled: true
        fsync: false
  cache:
    test-cache:
      merkle-tree:
        enabled: true
        depth: 12
      data-persistence:
        enabled: true
        fsync: false
  jet:
    instance:
      lossless-restart-enabled: true
----
--
Java::
+
--
[source,java]
----
include::ROOT:example$/storage/SampleHotRestartConfiguration.java[tag=hrconf]
----
--
====
