= Serializing Objects and Classes
:description: For data to be sent over a network between cluster members and/or clients, it needs to be serialized into raw bytes. Hazelcast has many serialization options to choose from, depending on what you plan on doing with your data.
:page-aliases: interface-types.adoc, comparing-interfaces.adoc

{description}

You can store any primitive types in a Hazelcast data structure and Hazelcast will serialize them for you, using <<built-in, built-in serializers>>. However, to store custom classes or objects, you need to tell a cluster how to serialize and deserialize them when they are sent over the network. For example, you must serialize the following:

- Custom objects

- Tasks used by the executor service

- Some entry processors

== Serialization Options

[CAUTION]
.Deprecation Notice for Portable Serialization
====
Portable Serialization has been deprecated. We recommend you use Compact Serialization as Portable Serialization will be removed as of version 7.0.
====

Hazelcast offers the following serialization options:

[cols="3,3a,4a,1a"]
|===
| Serialization interface| Advantages| Disadvantages|Client support

| xref:compact-serialization.adoc[Compact Serialization]

| * Optimized for memory usage and efficiency

* Convenient, flexible, and can be used with no configuration

* No class required to implement an interface

* Supports schema evolution

* Partial deserialization is supported during queries and indexing

|* Specific to Hazelcast

* Schema is not part of the data but schema distribution
may incur costs on short-lived use cases

|All clients

| xref:serializing-json.adoc[`HazelcastJsonValue`]
| * No member-side coding required

|* Specific to Hazelcast

* Requires extra metadata to be stored on members.

|All clients

| xref:custom-serialization.adoc[Custom Serialization]
| * Does not require class to implement an interface

* Convenient and flexible

* Can be based on `StreamSerializer` or `ByteArraySerializer`
|* Must implement serialization interface

* Requires plug-in and configuration

|All clients
|===

.Other alternative serialization options
[%collapsible]
====
[cols="3,3a,4a,1a"]
|===
| Serialization interface| Advantages| Disadvantages|Client support

| xref:implementing-dataserializable.adoc[`IdentifiedDataSerializable`]
| * More efficient CPU and memory usage than `Serializable`

* Reflection is not used during deserialization

| * Specific to Hazelcast

* Must implement serialization interface

* Must implement and configure a factory

|All clients

| xref:implementing-dataserializable.adoc[`DataSerializable`]
| * More efficient CPU and memory usage than `Serializable`
| * Specific to Hazelcast

|Java only

| xref:implementing-java-serializable.adoc[`Serializable`]
| * A standard and basic Java interface

* Requires no implementation
| * More time and CPU usage

* More space occupancy

|Java only

| xref:implementing-java-serializable.adoc[`Externalizable`]
| * A standard Java interface

* More CPU and memory usage efficient than `Serializable`
| * Must implement serialization interface

|Java only

| xref:implementing-portable-serialization.adoc[`Portable`] (deprecated)

| * More efficient CPU and memory usage than `Serializable`

* Reflection is not used during deserialization

* Versioning is supported

* Partial deserialization is supported during queries

| * Specific to Hazelcast

* Must implement serialization interface

* Must implement and configure a factory

* Class definition is also sent with data but stored only once per class

|All clients
|===

CAUTION: Portable Serialization has been deprecated. We recommend you use Compact Serialization as Portable Serialization will be removed as of version 7.0.

====

[[steps]]
== How Hazelcast Serializes Objects

When Hazelcast serializes an object:

. It first checks whether the object is `null`.
. If the above check fails, then Hazelcast looks for a user-specified xref:compact-serialization.adoc#implementing-compactserializer[CompactSerializer].
. If the above check fails, then Hazelcast checks if it is an instance of `com.hazelcast.nio.serialization.DataSerializable` or `com.hazelcast.nio.serialization.IdentifiedDataSerializable`.
. If the above check fails, then Hazelcast checks if it is an instance of `com.hazelcast.nio.serialization.Portable`.
. If the above check fails, then Hazelcast checks if it is an instance of one of
the default types.
. If the above check fails, then Hazelcast looks for a user-specified xref:custom-serialization.adoc[Custom Serializer],
i.e. an implementation of `ByteArraySerializer` or `StreamSerializer`.
Custom serializer is searched using the input Object's Class and its parent class up to Object.
If parent class search fails, all interfaces implemented by the class are also checked (excluding `java.io.Serializable` and `java.io.Externalizable`).
. If the above check fails, then Hazelcast checks if it is an instance of `java.io.Serializable` or
`java.io.Externalizable` and a Global Serializer is not registered with Java Serialization Override feature.
. If the above check fails, Hazelcast uses the registered Global Serializer if one exists.
. If the above check fails, then Hazelcast tries to extract a schema out of the Object's class xref:compact-serialization.adoc#using-compact-serialization-with-zero-configuration[automatically], if possible.

If all the above checks fail, then serialization fails.
When a class implements multiple interfaces, the above steps are important
to determine the serialization mechanism that Hazelcast uses.
When a class definition is required for any of these serializations, you need to have
all the classes needed by the application on your classpath because Hazelcast does not
download them automatically, unless you are using xref:clusters:deploying-code-on-member.adoc[user code deployment].

include::clusters:partial$ucn-migrate-tip.adoc[]

== Data Types with Built-In Serialization

By default, Hazelcast optimizes the serialization for the following data types. You do not need to serialize or deserialize these types yourself:

* `Class`, `Optional`, `Date`, `BigInteger`, `BigDecimal`, `ArrayList`, `LinkedList`, `CopyOnWriteArrayList/Set`, `HashMap/Set`,
`ConcurrentSkipListMap/Set`, `ConcurrentHashMap`, `LinkedHashMap/Set`, `TreeMap/Set`, `ArrayDeque`, `LinkedBlockingQueue`,
`ArrayBlockingQueue`, `PriorityBlockingQueue`, `PriorityQueue`, `DelayQueue`, `SynchronousQueue`, `LinkedTransferQueue`

If you would rather implement your own serialization for these types, you can configure Hazelcast to xref:serialization-configuration.adoc#override[enable overriding the default serializers].
