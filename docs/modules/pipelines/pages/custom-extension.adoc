= Create a Custom Stage Extension

It is possible to implement custom reusable Pipeline API stage extensions.
This tutorial is based on `PythonExtension` available in Hazelcast and walks step-by-step
how it is created.
You can check the whole production-ready implementation in the Hazelcast repository.

== Step 1. Define supported stage types

First step is to decide to what stages the extension will be applicable.
It is done by implementing `StageExtension` interface from appropriate Stage class.
Most commonly `StreamStage` and `BatchStage` will be used and often it is relatively easy
to implement extension for both kinds of stages and it makes it more flexible.
In some cases you may want to also support `StreamStageWithKey` and `BatchStageWithKey`.

[source,java]
----
public interface PythonExtension extends
        StreamStage.StageExtension<String, /*...*/>,
        BatchStage.StageExtension<String, /*...*/> {
            // ...
}
----

The Python extension supports both stream and batch stage.
Python transformation works only with `String`.
In more general cases this should be a generic type parameter.

== Step 2. Define API for the extension

Next you need to define the fluent API that will be available thank to the extension.
It is recommended to use interfaces to clearly separate API from implementation.

Usually the extension will ultimately return to the original `StreamStage` and `BatchStage` API,
but possibly with changed item type eg. due to mapping performed via extension.

[source,java]
----
public interface PythonExtension extends
        StreamStage.StageExtension<String, PythonExtension.PythonStage<StreamStage<String>>>,
        BatchStage.StageExtension<String, PythonExtension.PythonStage<BatchStage<String>>> {     // (1)

        interface PythonStage<S extends GeneralStage<String>> {   // (2)
            S map(PythonServiceConfig cfg);                       // (3)
        }
}
----

The example Python extension supports only single `map` method *(3)*.
In order to handle both `StreamStage` and `BatchStage` in type-safe way we use generic `S` parameter *(2)*
so that `map` method returns correct stage type (stream or batch) for further chaining.

`StageExtension` needs to know the type that will be used as stage API for extensions, so it is configured in *(1)*.

== Step 3. Define entry point for the extension

Static parameterless method *(1)* is a recommended way to provide entry point to the extension for `stage.using` invocation
as it can be statically imported and produces a readable, fluent syntax.

Note that the method provides implementations for different stage types *(2)* - appropriate implementation will be chosen automatically.
If there are generic types (e.g. stream item type), they should be properly inferred avoiding the need to specify them explicitly.

[source,java]
----
public interface PythonExtension extends
        StreamStage.StageExtension<String, PythonExtension.PythonStage<StreamStage<String>>>,
        BatchStage.StageExtension<String, PythonExtension.PythonStage<BatchStage<String>>> {

    static PythonExtension python() {       // (1)
        return new PythonExtensionImpl();   // (2)
    }
}

final class PythonExtensionImpl implements PythonExtension {
}
----

== Step 4. Implement the extension

There are two pieces left to be implemented: the extension class (`PythonExtensionImpl`) and the custom stage (`PythonStage`).

[source,java]
----
final class PythonExtensionImpl implements PythonExtension {

    @Override
    public PythonStage<StreamStage<String>> extend(StreamStage<String> streamStage) {  // (1)
        return new GeneralPythonStage<>(streamStage);
    }

    @Override
    public PythonStage<BatchStage<String>> extend(BatchStage<String> batchStage) {     // (2)
        return new GeneralPythonStage<>(batchStage);
    }
}

static class GeneralPythonStage<S extends GeneralStage<String>> implements PythonStage<S> {
    private final S stage;

    GeneralPythonStage(S stage) {
        this.stage = stage;    // (3)
    }

    @Override
    public S map(PythonServiceConfig cfg) {
        return (S) stage.mapUsingServiceAsyncBatched(       // (4)
                PythonService.factory(cfg), PythonTransforms.DEFAULT_MAX_BATCH_SIZE, PythonService::sendRequest)   // (5)
                .setName("mapUsingPython");
    }
}
----

Extension class is just an implementation of a visitor pattern *(1)* *(2)* that creates appropriate custom stage implementation.
It gets a reference to current stage in the pipeline which can be used to implement the extensions logic using existing infrastructure,
for example `mapUsingService`.

The custom stage remembers the `stage` *(3)* so it can be used to implement the `map` method.
`map` methods invokes standard `mapUsingServiceAsyncBatched` method *(4)* wiring extension-specific logic (service factory, mapping method) *(5)*.
The created stage is returned, so it is possible to use standard `Stage` methods like `setName` or `setLocalParallelism` to customize the just-created stage.


The result must be cast to `S` because in this context `mapUsingServiceAsyncBatched` returns `GeneralStage` *(4)*.
In case of Python extension, this will always be the same stage type: item type is still `String`
and `mapUsingServiceAsyncBatched` does not change `StreamStage` to `BatchStage`.
In general however, especially if the item type changes, you may need to handle `StreamStage` and `BatchStage` explicitly.
You can see how this can be implemented for example in  `mapUsingImap`:

1. `GeneralStage` provides base method definitions, javadoc and some shared default implementations. Methods return `GeneralStage`
2. `StreamStage` and `BatchStage` override the methods to return correct stage type, invoke base method and cast the result

== Step 5. Test the extension

Extensions can be tested by using them in a test pipeline.

The extension invocation `(1)` is very simple: `stage.using(python()).map(cfg)`.
Note that `setLocalParallelism` is not provided by Python extensions but by standard Stage.

[source,java]
----
import static com.hazelcast.jet.python.PythonExtension.python;

public void streamStage_mapUsingPython_extension() {
    // Given
    PythonServiceConfig cfg = new PythonServiceConfig()
            .setBaseDir(baseDir.toString())
            .setHandlerModule("echo")
            .setHandlerFunction("handle");
    List<String> items = IntStream.range(0, ITEM_COUNT).mapToObj(Integer::toString).collect(toList());
    Pipeline p = Pipeline.create();
    var stage = p.readFrom(TestSources.items(items)).addTimestamps(x -> 0, 0);

    // When
    var mapped = stage.using(python()).map(cfg).setLocalParallelism(2);     // (1)

    // Then
    mapped.writeTo(AssertionSinks.assertAnyOrder(
            "Python didn't map the items correctly", items.stream().map(i -> "echo-" + i).collect(toList())
    ));
    instance().getJet().newJob(p).join();
}
----

== Step 6. Add more capabilities

Once the basic structure works, you can add more methods and capabilities.
You can leverage the fact that you control the return type, so any fluent API can be implemented as long as you ultimately return to one of the standard stages.

Python extension for example has a fluent builder API to prepare `PythonServiceConfig` on the fly:

[source,java]
----
StreamStage<String> sourceStage;
var mapped = sourceStage.using(python())
        .baseDir("/tmp")
        .handlerModule("echo")
        .handlerFunction("handle")
        .maxBatchSize(1)
        .map().setLocalParallelism(2);
----