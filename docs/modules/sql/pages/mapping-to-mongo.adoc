= Mapping to MongoDB
:description: To query MongoDB data connections, you can create a mapping to them with the Mongo connector.
:page-beta: true

{description}

== What is the Mongo Connector

The Mongo connector allows you to read from/write to a MongoDB database, and to execute SQL queries on Mongo collections directly from Hazelcast.

== Supported SQL Statements

For the xref:integrate:mongodb-connector.adoc#batch[batch mode]:

- xref:select.adoc[`SELECT`]
- xref:update.adoc[`UPDATE`]
- xref:sink-into.adoc[`INSERT INTO/SINK INTO`]

For the xref:integrate:mongodb-connector.adoc#stream[streaming mode]:

- xref:select.adoc[`SELECT`]

== Installing the Connector

The Mongo Connector artifacts are published on the Maven repositories.
Add the following lines to your `pom.xml` to include it as a dependency to your project:

[source,xml,subs="attributes+"]
----
<dependency>
    <groupId>com.hazelcast.jet</groupId>
    <artifactId>hazelcast-jet-mongodb</artifactId>
    <version>${full-version}</version>
</dependency>
----

or if you are using Gradle:

[source,plain,subs="attributes+"]
----
compile group: 'com.hazelcast.jet', name: 'hazelcast-jet-mongodb', version: ${full-version}.
----

NOTE: To be able to use SQL over MongoDB, you have to include `hazelcast-sql` as well as a dependency.

== Permissions
[.enterprise]*Enterprise*

The Mongo connector does not yet support permissions.

== Before you Begin

Before you can create a mapping to a MongoDB, you must have the following:

* A `$jsonSchema` validation in the collection (see the https://www.mongodb.com/docs/manual/reference/operator/query/jsonSchema/[schema documentation]), or you have to have at least one element in the collection you want to create mapping for (for property type validation).
* Enabled operations log (oplog) if you want to use streaming mappings.

== Creating a MongoDB Mapping

The following example creates a mapping to a MongoDB database.

. In a MongoDB database, create a `people` collection. For example in Java, you would run the following command.
+
[source,java]
----
CreateCollectionOptions options = new CreateCollectionOptions();
ValidationOptions validationOptions = new ValidationOptions();
validationOptions.validator(BsonDocument.parse(
       "{\n" +
               "    $jsonSchema: {\n" +
               "      bsonType: \"object\",\n" +
               "      title: \"Object Validation\",\n" +
               "      properties: {" +
               "        \"personId\": { \"bsonType\": \"int\" },\n" +
               "        \"name\": { \"bsonType\": \"string\" }\n" +
               "      }\n" +
               "    }\n" +
               "  }\n"
));
options.validationOptions(validationOptions);
database.createCollection(collectionName, options);
----
The `ValidationOptions` are not required, but recommended.
. Configure the data connection so that the client can be reused by multiple mappings.
+
[tabs] 
==== 
XML:: 
+ 
-- 
[source,xml]
----
<hazelcast>
    <data-connection name="myMongo">
        <type>Mongo</type>
        <properties>
            <property name="connectionString">stringForMongo</property> <1>
        </properties>
        <shared>false</shared> <2>
    </data-connection>
</hazelcast>
----
--

YAML::
+
[source,yaml]
----
data-connection:
  name: myMongo
  type: Mongo
  properties:
    connectionString: stringforMongo <1>
  shared: false <2>
----

Java::
+
[source,java]
----
DataConnectionConfig dataConnectionConfig = new DataConnectionConfig()
        .setName("myMongo")
        .setType("Mongo")
        .setProperty("connectionString", connectionStringToMongo) <1>
        .setShared(false); <2>
config.addDataConnectionConfig(dataConnectionConfig);
----
====
<1> Your connection string.
<2> Set to `true` if the connection is reusable.
+
Instead of providing a single `connectionString` parameter, you may also want to provide host, username, password and (optionally) `authDb`.
+
Instead of providing the configuration in YAML or XML, you can also run the following SQL query.
+
[source,xml]
----
CREATE DATA CONNECTION myMongo type Mongo SHARED
OPTIONS (
	‘connectionString’ = ‘<your connection string>’
)
----
+
. Create the mapping.
+
[source,sql]
----
CREATE MAPPING people
DATA CONNECTION myMongo; <1>
----
<1> The name of the data connection configuration on your members (see Step 2 above).
+
In the above case, automatic schema inference will be used. You may also want to provide the schema explicitly as shown below.
+
[source,sql]
----
CREATE MAPPING people (
    firstName VARCHAR(100),
    lastName VARCHAR(100),
    age INT
)
DATA CONNECTION myMongo
----
Notice that there is no mention of `TYPE MONGO` this time; it’s automatically assumed by the SQL engine when you provide MongoDB data connection. This works with both schema provided or not.


[NOTE]
====
You have to specify the database name using one of the following options:

* add `OPTIONS ('database' = 'myDatabase')` in `CREATE DATA CONNECTION`
* add `OPTIONS ('database' = 'myDatabase')` in `CREATE MAPPING`
* use the full external name, e.g., `CREATE MAPPING people EXTERNAL NAME myDatabase.people (...)`
====

== Supported Object Types

For given connector there may be 1 or more object types. For Mongo SQL Connector we have 2 object types:

 - `Collection` - represents batch raeding from given collection. This is the default object type.
 - `ChangeStream` - represents reading a stream of events.

To change object type you want to use, you have to append `OBJECT TYPE X` after `DATA CONNECTION` / `TYPE`, for example:

[tabs]
====
Using Data Connection::
[source,sql]
----
CREATE MAPPING people (
    firstName VARCHAR(100),
    lastName VARCHAR(100),
    age INT
)
DATA CONNECTION myMongo
OBJECT TYPE ChangeStream
OPTIONS (...)
----

Using TYPE::
[source,sql]
----
CREATE MAPPING people (
firstName VARCHAR(100),
lastName VARCHAR(100),
age INT
)
TYPE Mongo
OBJECT TYPE ChangeStream
OPTIONS (...)
----
====

== Field mappings

Object type `Collection` reads columns to be the same as properties in Mongo collection.

For `ChangeStream` it's more complicated: the ChangeStream objects have Mongo collection's properties prefixed with `fullDocument.`,
There are also some predefined, top-level (without `fullDocument.` prefix) columns

 - `operationType STRING` - operation that triggered this Change event, e.g. `insert`
- `resumeToken STRING` - resume token associated with given change stream event.
- `wallTime DATE_TIME` - wall time of the event.
- `ts TIMESTAMP` - Timestamp of when the even occurred, either equal to wall time or to current time on the Hazelcast node,
  if no wall time was provided.
- `clusterTime TIMESTAMP` - cluster time on which this even occurred.

== Type Mapping

The type system in MongoDB and SQL is not exactly the same. That leads to potential confusions and the need of type coercion.

.MongoDB Type Conversion
[cols="1,1,1"]
|===
| BSON Type | SQL Type | Java Type

|`DOUBLE`
|`DOUBLE`
|`DOUBLE`

|`STRING`
|`VARCHAR`
|`STRING`

|`OBJECT`
|`OBJECT`
|`org.bson.Document`

|`ARRAY`
|`OBJECT`
|`LIST`

|`BINDATA`
| -
| -

|`UNDEFINED`
| -
| -

|`OBJECTID`
|`OBJECT`
|`org.bson.ObjectId`

|`BOOL`
|`BOOLEAN`
|`BOOLEAN`

|`DATE`

This represents seconds from Unix epoch in UTC timezone. Therefore, it's not mapped to pure `DATE` SQL type nor `LOCALDATE` in Java (nor any formats with timezones).
|`DATE_TIME` or `TIMESTAMP`
|`LOCALDATETIME`

|`TIMESTAMP`
|`DATE_TIME` or `TIMESTAMP`
|`LOCALDATETIME`

|`NULL`
| -
| -

|`REGEX`
|`OBJECT`
|`org.bson.BsonRegularExpression`

|`DBPOINTER`
| -
| -

|`JAVASCRIPT`
|`VARCHAR`
|`STRING`

|`JAVASCRIPTWITHSCOPE`
|`OBJECT`
|`org.bson.CodeWithScope`

|`SYMBOL`
| -
| -

|`INT (32 BIT)`
|`INT`
|`INT`

|`LONG (64 BIT)`
|`BIGINT`
|`LONG`

|`DECIMAL (128 BIT)`
|`DECIMAL`
|`BIGDECIMAL`

|`MINKEY`
|`OBJECT`
|`org.bson.MinKey`

|`MAXKEY`
|`OBJECT`
|`org.bson.MaxKey`
|===

The **Java Type** column represents an object returned by the SQL query if the object put into the collection is of given BSON type.

Note that, while Hazelcast is able to convert MongoDB type to the requested SQL type in the projection, the argument binding will not always work the same due to technical limitations. For example, you can have an object with the type `TIMESTAMP` represented as `DATE_TIME`, that after execution of `SELECT` it will give you `LocalDateTime` in Java client. However, binding `LocalDateTime` as an argument will not work, as only native MongoDB types will work for arguments. Same applies to, for example, having BSON column of type `STRING` mapped to `INTEGER` in SQL.

=== Type Coercion

The following table shows the possible and supported type coercions. All the default mappings from the previous section are always valid.

.MongoDB Type Conversion
[cols="m,m"]
|===
| Type of Provided Argument | Resolved Insertion Type

|`LOCALDATETIME`
|`BSONDATETIME`

|`OFFSETDATETIME`
|`BSONDATETIME`

|`HazelcastJsonValue` (JSON column)
|`DOCUMENT`
|===
