= CPU Thread Affinity

Hazelcast offers configuring CPU threads so that you have a lot better control
on the latency and a better throughput. This configuration provides you
with the CPU thread affinity, where certain threads can have affinity for particular CPUs.

The following affinity configurations are available for a member:

```
-Dhazelcast.io.input.thread.affinity=1-3
-Dhazelcast.io.output.thread.affinity=3-5
-Dhazelcast.operation.thread.affinity=7-10,13
-Dhazelcast.operation.response.thread.affinity=15,16
```

The following affinity configurations are available for a client:

```
-Dhazelcast.client.io.input.thread.affinity=1-4
-Dhazelcast.client.io.output.thread.affinity=5-8
-Dhazelcast.client.response.thread.affinity=7-9
```

You can set the CPU thread affinity properties shown above only on the command line. 

Let's have a look at how we define the values for the above configuration
properties:

* **Individual CPUs**, e.g., `1,2,3`: This means there are going to be
three threads. The first thread runs on CPU 1, the second thread on CPU 2, and so on.
* **CPU ranges**, e.g., `1-3`: Shortcut syntax for `1,2,3`.
* **Group**, e.g., `[1-3]`: This configures three threads and each of
these threads can run on CPU 1, 2 and 3.
* **Group with thread count**, e.g., `[1-3]:2`: This configures two
threads and each of these two threads can run on CPU 1, 2 and 3.

You can also combine those, e.g., `1,2,[5-7],[10,12,16]:2`.

Note that, the syntax for CPU thread affinity shown above not only determines
the mapping of CPUs to threads, it also determines the thread count.
If you use CPU thread affinity, e.g., `hazelcast.io.input.thread.affinity`,
then `hazelcast.io.input.thread.count` is ignored. See xref:threading-model.adoc#io-threading[Threading Model] for more
information on specifying explicit thread counts.

If you don't configure affinity for a category of threads, it means they can run on any CPU.

Let's look at an example. Assuming you have the `numactl` utility, run
the following command on your machine to see the mapping between the NUMA
nodes and threads:

```
numactl --hardware
```

An example output is shown below:

```
available: 2 nodes (0-1)
node 0 cpus: 0 1 2 3 4 5 6 7 8 9 20 21 22 23 24 25 26 27 28 29
node 0 size: 393090 MB
node 0 free: 372729 MB
node 1 cpus: 10 11 12 13 14 15 16 17 18 19 30 31 32 33 34 35 36 37 38 39
node 1 size: 393216 MB
node 1 free: 343296 MB
node distances:
node   0   1 
  0:  10  21 
  1:  21  10 
```

If you want to configure 20 threads on NUMA node 0 and 20 threads on NUMA node 1,
and confine the threads to these NUMA nodes, you can use the following configuration:

```
-Dhazelcast.operation.thread.affinity=[0-9,20-29],[10-19,30-39]
```

See https://en.wikipedia.org/wiki/Non-uniform_memory_access[here^]
for information on NUMA nodes.