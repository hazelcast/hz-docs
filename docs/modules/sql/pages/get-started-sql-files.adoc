= Get Started with SQL Over Files
:description: In this tutorial, you learn the basics of querying files in SQL by creating and querying a CSV file.

{description}

== Before You Begin

To complete this tutorial, you need the following:

[cols="1a,1a"]
|===
|Prerequisites|Useful resources

|A Hazelcast cluster in client/server mode and an instance of Management Center running on your local network.
|xref:getting-started:get-started-binary.adoc[Start a Local Cluster].

|A connection to the SQL shell
|xref:connecting-to-sql.adoc[]
|===

[.interactive-button]
xref:interactive-sql-files.adoc[Try the interactive example,window=_blank]

== Step 1. Create a Data Source to Query

SQL can query data in maps, Kafka topics and the local cluster's file system.

In this step, you create a CSV file that you can use to query. 

. Create a file named `likes.csv`.

. Add the following data to your file.
+
[source,shell]
----
msg_id,likes,dislikes
1,20,13
2,108,25
3,122,73
4,9,88
5,51,42
----
+
This example file contains a record of the number of likes each person has.

== Step 2. Create a Mapping to the File

To allow Hazelcast to find and recognize the data in your CSV file, you need to create a mapping to it.

In the SQL shell, use the xref:sql:create-mapping.adoc[`CREATE MAPPING` statement] to configure the file connector and give Hazelcast access to the data in the `likes.csv` file.

[source,sql]
----
CREATE MAPPING csv_likes (msg_id INT, likes INT, dislikes INT)
TYPE File
OPTIONS ('format'='csv',
    'path'='/absolute/path/to/current/directory', 'glob'='likes.csv');
----

TIP: Make sure you replace the `path` option with the absolute path to your CSV file.

== Step 3. Run Ad-Hoc Queries

Ad-hoc queries allow you to retrieve a small subset of data. Usually these queries are simple and you can have many of them running concurrently in a Hazelcast cluster.

. Use a xref:sql:select.adoc[`SELECT` statement] to query all the data in the `likes.csv` file.
+
[source,sql]
----
SELECT * FROM csv_likes;
----
+
You should see the following:
+
[source,shell]
----
+------------+------------+------------+
|      msg_id|       likes|    dislikes|
+------------+------------+------------+
|           1|          20|          13|
|           4|           9|          88|
|           3|         122|          73|
|           2|         108|          25|
|           5|          51|          42|
+------------+------------+------------+
----

. Query only the `msg_id` and `likes` columns, by adding them as a comma-separated list after the `SELECT` statement.
+
[source,sql]
----
SELECT msg_id, likes FROM csv_likes;
----
+
```
+------------+------------+
|      msg_id|       likes|
+------------+------------+
|           1|          20|
|           3|         122|
|           4|           9|
|           2|         108|
|           5|          51|
+------------+------------+
```

. Use a filter to display only the message numbers with more than 50 likes.
+
[source,sql]
----
SELECT msg_id FROM csv_likes WHERE likes >50;
----
+
```
+------------+
|      msg_id|
+------------+
|           2|
|           5|
|           3|
+------------+
```

. Give the `msg_id` column an alias for the query results.
+
NOTE: This clause does not rename the column in the table.
+
[source,sql]
----
SELECT msg_id AS message_number, likes, dislikes
FROM csv_likes
WHERE likes > 20;
----
+
```
+--------------+------------+------------+
|message_number|       likes|    dislikes|
+--------------+------------+------------+
|             2|         108|          25|
|             3|         122|          73|
|             5|          51|          42|
+--------------+------------+------------+
```

. To filter rows on more than one condition, you can join conditions with the `AND`, `OR`, and `NOT` operators.
+
[source,sql]
----
SELECT *
FROM csv_likes
WHERE likes > 100 OR dislikes < 30;
----
+
```
+------------+------------+------------+
|      msg_id|       likes|    dislikes|
+------------+------------+------------+
|           1|          20|          13|
|           2|         108|          25|
|           3|         122|          73|
+------------+------------+------------+
```
+
[source,sql]
----
SELECT *
FROM csv_likes
WHERE likes > 100 AND dislikes < 30;
----
+
```
+------------+------------+------------+
|      msg_id|       likes|    dislikes|
+------------+------------+------------+
|           2|         108|          25|
+------------+------------+------------+
```

If you need more control over how your data is being transformed and aggregated, you may want to xref:pipelines:overview.adoc[build a pipeline with the Jet API].

== Step 4. Run Federated Queries

Federated queries are those that join tables from different datasets.

Normally, querying in SQL is database or dataset-specific. However, Hazelcast, you can pull information from different sources and present a more complete picture of the data.

. Configure the map connector to create a new table called `dislikes`.
+
[source,sql]
----
CREATE MAPPING names
TYPE IMap OPTIONS ('keyFormat'='int', 'valueFormat'='varchar');
----
+
This table is mapped to a distributed map in Hazelcast where the key is an integer and the value is a string. 

. Use `SINK INTO` statements to add some entries to the map.
+
[source,sql]
----
SINK INTO names VALUES
(1, 'Greg'),
(2, 'Jerry'),
(3, 'Mary'),
(4, 'Jerry'),
(5, 'Joe');
----

. Use the xref:sql:select.adoc#join-tables[`JOIN` clause] to merge results from the `messages` and `names` tables so you can see who has the most likes and dislikes.
+
NOTE: The data source on the right of the join must always be a map.

+
[source,sql]
---- 
SELECT names.this, csv_likes.likes, csv_likes.dislikes
FROM csv_likes
JOIN names
ON csv_likes.msg_id = names.__key;
----
+
```
+--------------------+------------+------------+
|this               |       likes|    dislikes|
+--------------------+------------+------------+
|Jerry               |         108|          25|
|Greg                |          20|          13|
|Jerry               |           9|          88|
|Joe                 |          51|          42|
|Mary                |         122|          73|
+--------------------+------------+------------+
```

. Use the `ORDER BY` clause to order the results by name and use the `LIMIT` clause to limit them so that only the first two are displayed. Change the header of the names column to name.

[source,sql]
----
SELECT names.this AS name, csv_likes.likes, csv_likes.dislikes
FROM csv_likes
JOIN names
ON csv_likes.msg_id = names.__key
ORDER BY names.this
LIMIT 2;
----
+
```
+--------------------+------------+------------+
|name                |       likes|    dislikes|
+--------------------+------------+------------+
|Greg                |          20|          13|
|Jerry               |           9|          88|
+--------------------+------------+------------+

```

. Use the `SUM()` function to aggregate the total number of likes for each person and group the results by name.
+
[source,sql]
----
SELECT names.this AS name, sum(csv_likes.likes) AS total_likes 
FROM csv_likes 
JOIN names
ON csv_likes.msg_id = names.__key
GROUP BY name;
----
+  
You should see the following:
+
```
+--------------------+--------------------+
|name                |         total_likes|
+--------------------+--------------------+
|Greg                |                  20|
|Mary                |                 122|
|Joe                 |                  51|
|Jerry               |                 117|
+--------------------+--------------------+

```
+
The results do not include a row for each Jerry because the `GROUP BY` statement groups the results by name.

. Filter for the names that have more than 100 likes combined, using the `HAVING` clause. This clause is equivalent to the `WHERE` clause but for aggregate groups.
+
[source,sql]
----
SELECT names.this AS most_liked
FROM csv_likes 
JOIN names
ON csv_likes.msg_id = names.__key
GROUP BY names.this HAVING SUM(likes) > 100;
----
+
```
+--------------------+
|most_liked          |
+--------------------+
|Jerry               |
|Mary                |
+--------------------+
```

For a list of available aggregations, see xref:sql:expressions.adoc[].



== Step 5. Ingest Query Results into a Hazelcast Map

To save your query results as a view, you can cache them in Hazelcast by ingesting them into a map.

. Configure the map connector to create a new table called `likes_and_dislikes`.
+
[source,sql]
----
CREATE MAPPING likes_and_dislikes (
__key INT,
name VARCHAR,
likes INT,
dislikes INT
) TYPE IMap OPTIONS ('keyFormat'='int', 'valueFormat'='json-flat');
----
+
This table is mapped to a distributed map in Hazelcast where the key is an integer and the value is an object that's serialized to JSON.

. Run the `JOIN` query to merge results from the CSV file and the `dislikes` map and insert them into the `likes_and_dislikes` map.
+
[source,sql]
---- 
INSERT INTO likes_and_dislikes SELECT csv_likes.msg_id, names.this, csv_likes.likes, csv_likes.dislikes
FROM csv_likes
JOIN names
ON csv_likes.msg_id = names.__key;
----

. Make sure that the query results were added to the map.
+
[source,sql]
----
SELECT * FROM likes_and_dislikes
ORDER BY __key;
----
+
```
+------------+--------------------+------------+------------+
|       __key|name                |       likes|    dislikes|
+------------+--------------------+------------+------------+
|           1|Greg                |          20|          13|
|           2|Jerry               |         108|          25|
|           3|Mary                |         122|          73|
|           4|Jerry               |           9|          88|
|           5|Joe                 |          51|          42|
+------------+--------------------+------------+------------+
```

== Next Steps

Learn how to xref:querying-maps-sql.adoc[query maps with SQL].

Explore xref:sql:sql-statements.adoc[all available SQL statements].